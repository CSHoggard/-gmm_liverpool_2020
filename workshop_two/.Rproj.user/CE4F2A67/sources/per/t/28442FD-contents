---
title: "Geometric Morphometrics and Archaeological Science"
subtitle: "Workshop Two (July 2020)"
author: "Dr. Christian Steven Hoggard (University of Southampton, United Kingdom)"
output:
  pdf_document:
       latex_engine: xelatex 
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
```

## **Introductory remarks**

This guide provides a "hands-on" step-by-step introduction into the application of geometric morphometric (GMM) methodologies in archaeological science (as conducted through the R Environment). This guide will **provide an overview of some different methods of analysing landmark data, before detailing three case studies (using 2D and 3D landmark data)**.

We will spend roughly 3-5 minutes per 'chunk'. Chunks can be used as a means of rendering R output into documents, or to simply display code for illustration. The chunks presented here will minimise error resulting from manual input and ensure all participants are at the same stage. To run a 'chunk' (displayed as a shaded area and representing a function or suite of actions), we can press the "Run Selected Chunk" button, represented by a play button, or alternatively use the shortcut `ctrl + enter` on the highlighted code.  

For participants: **When you complete a function please use a "thumbs up" emoji on Slack. If there is an issue please raise your query in the Zoom Chat**. We are allowing time between functions to ensure that all participants (of varying R knowledge) can keep up; if you finish a particular process early please explore the functions in the packages used throughout this workshop, or individual functions through the 'Help' tab in the 'Packages' window.

This practical constitutes the second of three workshops on GMM and Archaeological Science, organised by Lucy Timbrell and Christopher Scott and led by Dr. Christian Steven Hoggard. This markdown, along with all resources (and recording of each workshop) can be found on the workshop GitHub repository: https://github.com/CSHoggard/-gmm_liverpool_2020.

We thank the Arts and Humanities Research Council North West Consortium Doctoral Training Partnership (AHRC NWCDTP) for supporting this workshop.

## **About the Code, Packages and Data**

One published dataset and two unpublished datasets are used in this workshop. The data from the first practical originates from: Vestergaard, C. and Hoggard, C.S. (2019). A Novel Geometric Morphometric (GMM) Application to the Study of Bronze Age Tutuli. *Danish Journal of Archaeology*, 8: 5-28. 

Data for this publication is stored on the Open Science Framework (https://osf.io/fcp43/) and is stored (for ease) on the workshop repository (https://github.com/CSHoggard/-gmm_liverpool_2020/tree/master/workshop_two). Data for the second and third case studies are unpublished and also stored on the workshop repository. This data is copyright protected under ownership law; please ask the repository owner (Dr. Christian Hoggard) for use beyond the remit of this workshop.

For this workshop we will be focusing on the analysis of two- and three-dimensional landmark data. The following packages are required:  

* **geomorph** v.3.3.1 (analysis of landmark data)  
* **Momocs** v.1.3.0 (analysis of landmark data)  
* **tidyverse** v.1.3.0 (visualisation of data)  
* **rio** v.0.5.16 (import files from GitHub)  

We are using the rio package and so we will not be required to download the data to a working directory and setting our RStudio accordingly (as is standard practice). Through the execution of all chunks in this markdown document all data will be imported, analysed and visualised.

Once R and RStudio have been installed, and this markdown file opened within RStudio (through `File` -> `Open file`), we need to install the aforementioned packages. For this workshop we will install these packages through the below 'chunk': 

```{r, chunk1, , eval=FALSE, echo=TRUE, message=FALSE, warning=FALSE}
install.packages('geomorph', repos='http://cran.us.r-project.org')
install.packages('Momocs', repos='http://cran.us.r-project.org')
install.packages('tidyverse', repos='http://cran.us.r-project.org')
install.packages('rio', repos='http://cran.us.r-project.org')
```

As the tidyverse and Momocs packages may take time to install given the size of the files *please ensure that these packages are downloaded prior the workshop*. Once installed we can now activate and use these packages through the `library()` function. 

```{r, chunk2, , eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
library(geomorph)
library(Momocs)
library(tidyverse)
library(rio)
```

## Case Study 1: Tutuli in the Nordic Bronze Age (2D)

In this first case study we will examine 375 tutuli from the Nordic Bronze Age (NBA). Tutuli are small circular plates and were originally thought to have been designed for practical purposes e.g. shield-buckles (Rafn 1856). More recently, archaeologists have argued that tutuli function as clothing accessories e.g. beltware and cape buttons (Bergerbrant 1999). Here we will focus on the strength of pre-existing classificatory schemes adopted by archaeologists, and address two questions. On the basis of pre-existing classificatory schemes: 

* How successful can the four groups (types A/C/D/E) be differentiated?  

* How successful can different shapes be attributed to different periods within the NBA?

28 two-dimensional landmarks were digitised (in tpsDig2) from professional illustrations of tutuli cross-sections (a demo will be provided). As these shapes are typically symmetric, and given their abundance in catalogues (Aner et al. 1973, 1976-1978, 1981, 1986, 1991, 1995, 2001, 2005, 2008, 2011, 2014, Aner and Kersten 1979; Aner, Kersten and Neumann 1984; Aner, Kersten and Koch 1990; Aner et al. 1993), these cross-section illustrations represent a source of great interpretive potential. Please refer to Vestergaard and Hoggard (2019) for any of the above references. 

To do this we will first import the data, perform the necessary data registration method (**Generalised Procrustes Analysis**), and explore the main sources of shape variation through a **Principal Component Analysis (PCA)**, before testing the robustness of these groups through a **MANOVA (Multivariate Analysis of Variance)** and **Discriminant Function Analysis (DFA)**. A variety of other analyses can be performed; these will be demonstrated (subject to time limit).

We will first import the data into the R Environment. As this data is .tps in format (with landmarks digitised in tpsDig2) we could use either `Geomorph::readland.tps` or `Momocs::import_tps()`. As we will use Momocs throughout this first case study the `Momocs::import_tps()` is your best choice (it is also more appropriate for class conversion in Momocs). As we are downloading this data from the GitHub repository we will use `rio::import` as follows:

```{r, chunk3, eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
tutuli_lm <- rio::import("https://github.com/CSHoggard/-gmm_liverpool_2020/raw/master/workshop_two/tutuli_lm.rds")

tutuli_data <- rio::import("https://github.com/CSHoggard/-gmm_liverpool_2020/raw/master/workshop_two/tutuli_data.rds")   

```

Note: for the purpose of this workshop I will detail in-text the function and its constitutent package e.g. `geomorph::readland.tps()`, however only the function is what we need to code e.g. `readland.tps()`. This helps you to understand what packages the functions originate from.  

With our data now in the R Environment we can now call our tps object through the `base:: View` functions. The `base::View()` function will highlight the three constituent parts of the tps file: the 1) *Coo* (coordinate data - generated in tpsDig2), 2) *cur* (the curve data if applicable - for sliders), and 3) *scale* (the scale data if present). It is the Coo data which we will take forward (size is not considered here).

We can first examine the database using the `utils::head()`.

```{r, chunk4, eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
head(tutuli_data)

```

In order to use examine the date and classifications columns later we require them to be of class *factor* (`<fct>`); at present they are `<chr>`, that is to say of type 'character', an object that contains character strings.  We can do this quite easily using the `base::as.factor()` argument on the specific column (which can be called using the dollar sign). We can then double-check to ensure they are of class factor with the `base::is.factor()`, as follows:

```{r, chunk5, echo = TRUE, message=FALSE, warning=FALSE}
tutuli_data$date <- as.factor(tutuli_data$date)
tutuli_data$classification <- as.factor(tutuli_data$classification)

is.factor(tutuli_data$date)
is.factor(tutuli_data$classification)

```

Finally, we can convert our artefact id column into the row names using the `tibble::column_to_rownames` function. Note: could have been performed during the .rds object creation.

```{r, chunk6, message=FALSE, warning=FALSE}
tutuli_data <- column_to_rownames(tutuli_data, var = "artefact_id")

```

Our database is now formatted appropriately.

Central to Momocs are a specific suite of shape classes, depending on the landmarking specific. These classes can be divided into three: 1) *outlines* (OutCoo), *open outlines* (OpnCoo) and *landmarks* (LdkCoo), with one class specific to your own dataset. While some operations in Momocs are generic and do not depend on one of these classes, many functions require your data to be one of these specific 'S3 objects'. In this instance our tps data is comprised of landmarks, and so we wish for our data to be `LdkCoo`, as to enable a Generalised Procrustes Analysis and subsequent exploratory and analytical procedures.  

The coordinate data (coo) must therefore be turned into outline data through the `Momocs::Ldk()` function for the workflow to work. Once performed, we can then enter the object (here titled 'tutuli_shape') and examine its properties. For landmark visualisation we can also input the links between the landmarks. This can be imported from a .csv file or a notepad file, however today we will create the links in-house, so to speak (note: this must be imported prior the `Momocs::Ldk()` function). The `base::rbind` function takes a series of vector data or a matrix and creates x number of columns. Each number corresponds to a landmark, with each paid being defined within one concatenated set of parentheses:

```{r, chunk7, message=FALSE, warning=FALSE}
outline<-rbind(c(1,2),c(2,3),c(3,4),c(4,5),c(5,6),c(6,7),c(7,8),c(8,9),c(9,10),c(10,11),c(11,12),c(12,13),c(13,14),c(14,15),c(15,16),c(16,17),c(17,18),c(18,19),c(19,20),c(20,21),c(21,22),c(22,23),c(23,24),c(24,25),c(25,26),c(26,27),c(27,28),c(28,1))
```

We can now perform the `Momocs::Ldk()` argument:

```{r, chunk8, message=FALSE, warning=FALSE}
ldk_tutuli <- Ldk(tutuli_lm$coo, links = outline, fac = tutuli_data)
```

Note: we need to call the coordinate component of the object. If we wish we can now call the object and observe that there are 375 landmark configurations, each with 28 landmarks. We can also use square parentheses to call up individual objects. For example, if we wish to see the coordinate data for item #3 we can use `[3]`:

```{r, chunk9, message=FALSE, warning=FALSE}
ldk_tutuli[3]
```

Now our data is in the R environment and in the appropriate class required for Momocs, we can examine the landmark configurations We can first look at all landmarks through the `Momocs::panel()` function (note: this will take some time and it is advised not to use this function during the workshop). We can also use the `Momocs::inspect()` and `Momocs::coo_plot()` functions for various other shape classes (we will focus on these next week with our outline data). But for example:  

```{r, chunk10, message=FALSE, warning=FALSE, fig.cap = "An example plot of the tutuli using the `Momocs::coo_plot()` function. The size and the shape of landmarks can be customised using the `cex` and `pch` arguments.", fig.dim = c(6,6)}
coo_plot(ldk_tutuli[8], cex = 1.5, pch = 20, col = "grey", poly = TRUE, centroid = FALSE, border = TRUE)
```

We can now remove all factors external to shape (scaling, translation and rotation) through a *Generalised Procruses Analysis*. In Momocs there are a number of Procrustes procedures we could implement:  

* *Full Generalised Procrustes* (`fgProcrustes`: default)  

* *Full Generalised Procrustes with sliding landmarks* (`Momocs::fgsProcrustes`)  

* *Full Generalised Procrustes between two shapes* (`Momocs::fProcrustes`)  

* *Partial Procrustes between two shapes* (`Momocs::pProcrustes`)  

Which procedure you use depends on the types of shapes you have (sliders vs. non-sliders) and the nature of the superimposition. We require the `Momocs::fgProcrustes` function for this particular dataset and process. This iterative process will return a number of useful components, including the number of iterations, the pairwise distance measures, the mean shape configuration and, if scale has been included, the centroid sizes. This object is now of class *LdkCoe* (landmark coefficients), this is important when considering what functions can be used in Momocs. Note: we could alternatively import and analyse our data through geomorph, using the `geomorph::readland.tps()` and `geomorph::gpagen()` functions.  

```{r, chunk11, message=FALSE, warning=FALSE}
gpa_tutuli <- fgProcrustes(ldk_tutuli, tol = 0.1)
```

Following this process we can visualise our shapes through the `Momocs::stack()` function. This image may appear variable, with landmarks failing to align, however there is great variability in the shapes of tutuli.  

```{r, chunk12, message=FALSE, warning=FALSE, fig.cap = "Generalised Procrustes Analysis (GPA) of all 375 tutuli (using the `Momocs::fgProcrustes` function). Note: the image may appear variable, with landmarks failing to align, however this is the result of great variability in the shapes of tutuli - see `Momocs::panel()`", fig.dim = c(5,5)}
stack(gpa_tutuli, title = "")
```

With our Procrustes-alligned coordinates we can now examine shape variance among all examples, and between-group shape variance (for period and classification).  

To examine the main sources of shape variation we will first perform a **Principal Component Analysis** (please refer to the first workshop for a detailed explanation of PCA). This procedure will allow us to understand the main sources of variation within our data, and how our groups (classification and date) map onto this morphospace. We can also begin to understand how much each source of variation contributes to the overall variation within a dataset.  

Our landmark coefficients first need to be of class 'PCA'. We will therefore use the `Momocs::PCA()` function (using `base::prcomp()`). As our factors are embedded within the procrustes coordinates (as we linked them at the beginning) we do not need to add them here. The code goes as follows:

```{r, chunk13, message=FALSE, warning=FALSE}
pca_tutuli <- PCA(gpa_tutuli)
```

Technical note: scaling and centering are `TRUE` by default (however this can be changed through the scale and center arguments).  

With the PCA object we can assess the contribution of each source of shape variation through a **scree table** and **scree plot** using the `Momocs::scree()` and `Momocs::scree_plot()` arguments.

```{r, chunk14, echo = TRUE, message=FALSE, warning=FALSE}
scree(pca_tutuli)
```

Here we can see that the first source of shape variance (the first principal component) accounts for 68.76% of all shape variation within our dataset, with the first six sources accounting for greater than 95% cumulative shape variance. We can also visualise this in bar graph form:  

```{r, chunk15, message=FALSE, warning=FALSE, fig.cap = "A scree plot of the first ten principal components (using the `Momocs::scree_plot()` function", fig.dim = c(5,5)}
scree_plot(pca_tutuli, 1:10)
```

We can now plot of PCA through the `Momocs::plot_PCA()` function. This plot highlights that the four different classifications can be teased apart quite successfully in the first two principal components. We can also see that first principal component extends from narrow thin-lipped tutuli to high-peaking tutuli, with the second principal component accounting for the cross-section cavity. Convex hulls are visualised to show the distribution of the group in its entirety, however these are prone to outliers and confidence ellipses would be a preferred visual tool (both can be achieved through the `Momocs::plot_PCA()` tools). Many of these arguments (from initialisation to visualisation) can be handled through Dplyr's forward-pipe operator (%>%). You can use this operator to pass the left-hand side input through the right-hand side operator (treat it as a 'and then' operative. This will be demonstrated during the practical, for teaching purposes we're taking the long way around.  

```{r, chunk16, message=FALSE, warning=FALSE, fig.cap = "A Principal Component Analysis (PC1 vs. PC2) of NBA tutuli. Colours correspond to classification *sensu* Montelius (1885).", fig.dim = c(6,6)}
plot_PCA(pca_tutuli, axes = c(1,2), ~classification, chull = FALSE, chullfilled = TRUE, morphospace_position = "range_axes", zoom = 1)
```

It is important to note that these sources are shape variation pertain to the entire group, and not specific groups. It is therefore important to examine other principal components in order to identify principal components which are good discriminators (i.e. those that are archaeologically relevant). The axes on this plot can be changes through amending the `axes = c(1,2)` argument to whichever principal components are best.  

We can repeat this process for periodisation, as follows:  

```{r, chunk17, message=FALSE, warning=FALSE, fig.cap = "A Principal Component Analysis (PC1 vs. PC2) of NBA tutuli. Colours correspond to period in the Nordic Bronze Age (NBA).", fig.dim = c(6,6)}
plot_PCA(pca_tutuli, axes = c(1,2), ~date, chull = FALSE, chullfilled = TRUE, morphospace_position = "range_axes", zoom = 1)
```

Again, clustering can be seen with each period of the Nordic Bronze Age with stage three featuring more negative PC1 vaues and stage two corresponding with more positive values.  
We can also visualise these principal components, and the variance within different archaeological units, in an alternative way, through the `Momocs::boxplot()` function. Boxplots have the advantage of condensing a multi-dimensional space into two axes (subject to graphical parameters). The code is as follows:  

```{r, chunk18, message=FALSE, warning=FALSE, fig.cap = "A Principal Component Analysis (PC1 vs. PC2) of NBA tutuli represented as a box-plot. Colours correspond to period in the Nordic Bronze Age (NBA).", fig.dim = c(6,6)}
boxplot(pca_tutuli, ~date, nax = 1:5)
```

If we wish, we can use `Momocs::plot_MSHAPES()` function for displaying the mean shapes for both factors. A variety of methods are available (using the `Momocs::coo_plot()` argument) however `Momocs::plot_MSHAPES()` is the most convenient method. Here I exemplify piping of mean shapes for classification:  

```{r, chunk19, message=FALSE, warning=FALSE, fig.cap = "Mean shapes of different tutuli classifications (as plotted through `Momocs::plot_MSHAPES()`", fig.dim = c(6,6)}
gpa_tutuli %>% MSHAPES(~classification) %>% plot_MSHAPES()
```

As we highlighted in the first workshop, PCA explores differences in shape variation irrespective of group composition (i.e. *a priori* groupings). Through a discriminant analysis we can examine differences in shape as based on their maximum group seperation (between-group variation in contrast to within-group variation). In Momocs, we use the `Momocs::LDA()` function on either the landmark coefficients (Procrustes Coordinates) or the PCA scores to produce our class accuracy, plots and correction scores. There is no correct answer as to which to use, it depends on the data you wish to examine. In using the PCA scores it is possible to retain a number of components that are deemed important, this can be either: 1) the first nth components, 2) the number of components representing a certain level of shape variance (e.g. 95%, 99%, 99.9%), or 3) all principal components. The coefficients, in contrast would encapsulate all shape data.  

With greater levels of data you may include a degree of statistical noise, with smaller unimportant variables taking precedence, and so an optimal level of data is necessary if you persue PCA scores (see Kovarovic et al. 2011 for more information).  

First we must create a LDA object (or alternatively perform piping):  


```{r chunk20, echo=TRUE, eval=TRUE, message=FALSE}
lda_tutuli_class <- LDA(gpa_tutuli, ~classification)
lda_tutuli_date <- LDA(gpa_tutuli, ~date)

```

We can now examine different aspects of our discriminant analysis data, including the cross-validation table (actual vs. predicted categories for artefacts) and the proportion of correctly classified individuals.  


```{r chunk21, echo=TRUE, eval=TRUE, message=FALSE}
lda_tutuli_class$CV.correct
lda_tutuli_class$CV.ce
lda_tutuli_date$CV.correct
lda_tutuli_date$CV.ce
```

When we use the `CV.correct` argument we see that 88.53% of tutuli can be appropriately differentiated by the Montelius system. We can examine this in further detail through the `CV.ce` argument. Higher percentages of success can be seen for groups D (96.37%) and A (92.65%), and admirable success rates for groups E (86.89%) and C (81.30%). For designated periodisation, these can be successfully discriminated 88% of the time with 92.36^ and 81.52% for the second and third parts of the NBA, and little success with the transitional and LBA examples (this is the result of an incredibly low sample size). Pursuing this further through Machine Learning methodologies for undoubtedly increase the success of these groups, and highly possible anomalies in their classification. `Momocs::classification_metrics()` is also a useful analytical and exploratory tool here.  

Finally, for this case study let's test our interpretations through a MANOVA (through PC scores). A Procrustes ANOVA could be conducted through geomorph, however as we have used Momocs throughout this first case study let's finish off here with a MANOVA (the next examples will perform a Procrustes ANOVA.  

For this we require the `Momocs::MANOVA()` function. Again, this can be piped using Dplyr's operator or done manually. A manual version would look like this:  

```{r chunk22, echo=TRUE, eval=TRUE, message=FALSE}
manova_tutuli_class <- MANOVA(pca_tutuli, ~classification)
manova_tutuli_date <- MANOVA(pca_tutuli, ~date)
manova_tutuli_class_pw <- MANOVA_PW(pca_tutuli, ~classification)
manova_tutuli_date_pw <- MANOVA_PW(pca_tutuli, ~date)
```

We have used the `Momocs::MANOVA_PW()` function to include pairwise values, highlighting the statistical relationships between factor sub-groups.  

```{r chunk23, echo=FALSE, eval=FALSE, message=FALSE}
manova_tutuli_class
manova_tutuli_date
manova_tutuli_class_pw
manova_tutuli_date_pw
```

These again highlight the degree with which different categories can be partitioned on the basis of cross-sectional shape. We can therefore conclude that the date and classification categories which archaeologists perscribe tutuli to work (that is not to say that they are chronologically correct just that the groupings work!).  

Option: now we are finished with this case we can remove all items from the environment with the `base::rm()` as below:

```{r chunk24, echo=TRUE, eval=FALSE, message=FALSE}
rm(list = ls())
```


## Case Study 2: Cranial Morphology vs. Sex (3D)

In this next case study we will investigate three-dimensional shape changes in cranial morphology, and the relationship between sex and cranial shape. As a simple demonstration we will use six crania (2 female and 4 male).  

In the previous case study we used Momocs to investigate our two-dimensional landmark data (in .tps format). It provided the most immediate form of analysis for our data, and allowed a number of interesting visualisations. In this example we will use geomorph to examine our three-dimensional data (in .ply ASCII format). Geomorph relies more on base R (in comparison to Momocs which is more 'tidy'), and so our grammar may change in areas.  

Files of .ply format can be fed into R through `geomorph::read.ply` through the sample code (providing that the data is saved to a working:

```{r chunk25, echo=TRUE, eval=FALSE, message=FALSE}
SK1 <- read.ply("skull_1.ply", ShowSpecimen = FALSE, addNormals = FALSE)
```

Note: The R package *Rvcg* is useful for importing your STL or binary PLT meshes into R and converting to Ascii PLY format.

With the SK1 object we can now begin digitising landmarks onto the cranium. In this case study we will digitise 23 landmarks (refer to the landmark guides and documentation in the GitHub repository). For increased resolution we will include 200 surface sliding semilandmarks. Please see Gunz et al. (2005) and Mitteroecker and Gunz (2009) for more information.  

In order to digitise our landmarks through this procedure we will first need to build a template for the digitisation of landmarks across specimens. This will be performed through the `geomorph::buildtemplate` function. This function requires an object of class mesh3d/shape3d (our .ply file), the number of fixed landmarks (23) and the number of surface.sliders (200). A graphical user interface (GUI) then appears allowing you to digitise your 23 landmarks; the 200 surface sliding landmarks will be automatically placed following this digitisation process (and for every subsequent specimen). Please refer to the R documentation (`?geomorph::buildtemplate`) for more information. This will be demonstrated throughout the workshop. I have included all six .ply files to allow digitisation following the workshop.  

The resulting object is stored in the R Environment, with an .nts file saved into the working directory. Once the first skull has been digitised you continue the process with the `geomorph::digitsurface()` function.  

When all the landmarks are digitised, and all .nts files created, we can feed them all in together using the `geomorph::readmulti.nts`. For the purpose of the practical this object has been created in an .rds file and will be imported from the workshop GitHub repository (like in the previous case study).

```{r chunk26, echo=TRUE, eval=TRUE, message=FALSE}
skull <- rio::import("https://github.com/CSHoggard/-gmm_liverpool_2020/raw/master/workshop_two/skull.rds")  
```

As you will observe in the environment the data is in *n* x *d* x *s*, with *n* being the number of landmarks in total, *d* being the dimensions explored, and *s* being the sample size. This is an array, a series of rows, columns and layers. In this example, if we wish to view a particular specimen we would use our square parentheses but this time include two commas (as we're interested in the third aspect of this array) e.g. for the first specimen we would code...  

```{r chunk27, echo=TRUE, eval=FALSE, message=FALSE}
skull[,,1]

#OR

# rgl.open()
# rgl.points(skull[,,1], r = 0.2)
```

If a sufficient number of examples were included we could also use the `geomorph::plotOutliers` argument to examine which specimens have a Procrustes Distance from the mean (incase of a landmarking issue, for example). 

A further two objects are necessary: the metadata (the .csv table with the skull data) and the slider file (denoting which landmarks slide). Again, with the the `rio::import()` function we can include them into this workspace:  

```{r chunk28, echo=TRUE, eval=TRUE, message=FALSE}
surface_lm_skull <- rio::import("https://github.com/CSHoggard/-gmm_liverpool_2020/raw/master/workshop_two/surface_lm_skull.rds") 

skull_data <- rio::import("https://github.com/CSHoggard/-gmm_liverpool_2020/raw/master/workshop_two/skull_data.rds") 
```

We need to inspect the skull_data to verify that are columns are correct. Using the `base::head()` function we realise we again need to convert our sex column into `factor` class (we will not worry about location as we are only investigating sex here). Like previous, we can use the `base::is.factor()` argument to verify that our change is correct.

```{r chunk29, echo=TRUE, eval=TRUE, message=FALSE}
head(skull_data)
skull_data$Sex <- as.factor(skull_data$Sex)
is.factor(skull_data$Sex)
```

With the landmarks imported into the R Environment, and our metadata in the correct format we can now begin registering our coordinate data through a Generalised Procrustes Analysis. Previously we used `Momocs::fgProcrustes()` with our two-dimensional coordinate data, for this dataset we will use the `geomorph::gpagen()` function. We input our landmark data and include our surface sliding semilandmark data.  

```{r chunk30, echo=TRUE, eval=TRUE, message=FALSE}
gpa_skull <- gpagen(skull, Proj = TRUE, ProcD = TRUE, curves = NULL, surfaces = surface_lm_skull, print.progress = F)
```

A class of gpagen data is returned. this includes the Procrustes coordinates, the centroid size, aspects of the dataset including the variance-covariance matrix and its format. We can inspect the result through the `graphics::plot()` function and customise the output using the rgl package.

```{r chunk31, echo=TRUE, eval=FALSE, message=FALSE}
plot(gpa_skull, mean = TRUE, label = FALSE, plot.param = list(pt.cex = 0.5, mean.bg = "red"))
```

We can now inspect variation in our skull shape through a PCA. In geomorph, a PCA is formed through the `geomorph::gm.prcomp()` argument, with the input being our Procrustes coordinates. If phylogenetic data is provided then a Phyogenetically-Aligned Principal Component Analysis (PaCA) can be performed, however we are using a traditional PCA based on OLS-centering and projection.

```{r chunk32, echo=TRUE, eval=TRUE, message=FALSE}
pca_skull <- gm.prcomp(gpa_skull$coords)
summary(pca_skull)
```

We can observe that in this example the first principal component accounts for 68.08% of all cumulative shape variation, with the first five components accounting for all variation (this is surprising as the number of components is limited by your degrees of freedom).

We can also look at the three-dimensional configurations of different aspects of the principal components through an investigation of the `$shapes` component of the object.

With this we can now plot our data in base R graphics as below (or use `rgl::plot.3d()` if we're being fancy! As our .nts files are in the correct order as the dataset we can attribute colour as attached. Match functions will be necessary if these are not alligned (with the id label mirrored in the .nts and dataset files).

```{r chunk33, echo=TRUE, eval=TRUE, message=FALSE}
plot(pca_skull, axis1 = 1, axis2 = 2, main = "Principal Component Analysis (PC1 vs. PC2)", pch = 19, cex  = 1.5, col = skull_data$Sex, font.lab = 2)
```

There are various means with which we can explore shape variation across PC space and visualising shape patterns. One way is through `geomorph::mshape()` and `geomorph::plotRefToTarget`. For example:

```{r chunk34, echo=TRUE, eval=FALSE, message=FALSE}
plotRefToTarget(pca_skull$shapes$shapes.comp1$min, pca_skull$shapes$shapes.comp1$max, method = "points")
```

We can perform a Procrustes ANOVA and test for statistical difference between our specimens. First an object which captures all the information (coordinates and sex) must be created.  

```{r chunk35, echo=TRUE, eval=TRUE, message=FALSE}
skulldf <- geomorph.data.frame(gpa_skull, sex = skull_data$Sex)
```

Once we have our data frame we can utilise the `geomorph::procD.lm()` and `stats::anova()` functions to test for statistical difference. If we use the `geomorph::procD.lm()` and create an object we can also extract QR compositions, fitted values and residuals (observed responses).

```{r chunk36, echo=TRUE, eval=TRUE, message=FALSE}
anova(procD.lm(coords ~ sex, data = skulldf))
```

Like the previous example, now we are finished with this case we can remove all items from the environment with the `base::rm()` as below:

```{r chunk37, echo=TRUE, eval=FALSE, message=FALSE}
rm(list = ls())
```

## Case Study 3: Patella morphology vs. sex (3D)

This final example is part of current research the author is conducting as part of the A Joint Effort project (https://twitter.com/UoSJointEffort), investigating the relationship in patella (kneecap) morphology, sex and behaviour.

For this final exercise 21 left-sided patellae are examined through three-dimensional geometric morphometrics. These patellae stem from a cemetery site and represent a vast array of ages and occupations. 12 female patellae and nine male patellae are here examined. 14 landmarks and 75 sliding surface semi-landmarks were digitised, corresponding to the above procedure. A variety of Type I, Type II and Type III landmarks were chosen, given the relatively few landmarks on patellae (please refer to the GitHub repository). An example patella accompanies the Github repository.  

Like before, we will download the dataset (with sex data), the sliding surface data and the .nts data through the functions in the rio package. A fourth file detailing the links between the landmarks is also included here. For reference:  

* *patella_dataset*: the .csv file (containing the metadata)  
* *patella_lm*: the multi.nts object (containing the landmark data)  
* *patella_links*: the links between landmarks (for visualisation)  
* *patella_surfslide*: the landmarks which are sliding surface semilandmarks  


```{r, chunk38, echo=TRUE, eval=TRUE, message=FALSE}
patella_dataset <- rio::import("https://github.com/CSHoggard/-gmm_liverpool_2020/raw/master/workshop_two/patella_dataset.rds")

patella_lm <- rio::import("https://github.com/CSHoggard/-gmm_liverpool_2020/raw/master/workshop_two/patella_lm.rds")

patella_links <- rio::import("https://github.com/CSHoggard/-gmm_liverpool_2020/raw/master/workshop_two/patella_links.rds")   

patella_surfslide <- rio::import("https://github.com/CSHoggard/-gmm_liverpool_2020/raw/master/workshop_two/patella_surfslide.rds")   

```

As before, we need to inspect the dataset and its attributes. An inspection of the dataset with `utils::head()` reveals that the sex column is character in type, and like before we require the data to be factor (fct) in nature. We also require our surface sliding semilandmarks to be in matrix form.

```{r chunk39, echo=TRUE, eval=TRUE, message=FALSE}
head(patella_dataset)
patella_dataset$sex <- as.factor(patella_dataset$sex)
is.factor(patella_dataset$sex)

patella_surfslide <- as.matrix(patella_surfslide)
```

With our data now in the R Environment we can now plot like previously, and conduct the Generalised Procrustes Analysis using the `geomorph::gpagen()` function.  

Using the usual graphical parameters... 

```{r chunk40, echo=TRUE, eval=FALSE, message=FALSE}
patella_lm[,,1]

# OR

# rgl.open()
# rgl.points(patella_lm[,,1], r = 0.2)
```

And for the Generalised Procrustes Analysis...  

```{r chunk41, echo=TRUE, eval=TRUE, message=FALSE}
gpa_patella <- gpagen(patella_lm, Proj = TRUE, ProcD = TRUE, curves = NULL, surfaces = patella_surfslide)
```

We can now examine the Procrustes coordinates:  

```{r chunk42, echo=TRUE, eval=FALSE, message=FALSE}
plot(gpa_patella, links = patella_links, plot.param = list(pt.cex = 0.5, mean.cex = 5, mean.bg = "red"))
```

All our specimens appear to plot correctly, with the landmarks correctly plotted and the Generalised Procrustes Analysis a success. Now we can use these Procrustes coordinates to create a Principal Component Analysis, and investigate sources of shape variation between sex.  

```{r chunk43, echo=TRUE, eval=TRUE, message=FALSE}
pca_patella <- gm.prcomp(gpa_patella$coords)
summary(pca_patella)
```

Interestingly our principal components, individually and as a percentage of cumulative shape variance, are much lower than our previous case studies with the first four principal components totalling slightly higher of 50%. This may be because there are more nuanced changes in patella shape throughout the chosen examples.  

```{r chunk44, echo=TRUE, eval=TRUE, message=FALSE}
plot(pca_patella, axis1 = 1, axis2 = 2, main = "Principal Component Analysis (PC1 vs. PC2)", pch = 19, cex  = 1.5, col = patella_dataset$sex, font.lab = 2)
```

Alternatively, we may wish to plot these scores within a 'tidy' framework i.e. using the graphical principles of the tidyverse package. To do so, a number of procedures are first necessary. We must isolate the principal component scores and our data, convert them into tibble (a new kind of data frame format), and then bind together. The process is as follows:

```{r chunk45, echo=TRUE, eval=TRUE, message=FALSE}
pca.scores <- as_tibble(pca_patella$x, rownames = "rownames") %>% column_to_rownames("rownames")
data <- as_tibble(patella_dataset, rownames = "rownames") %>% column_to_rownames("rownames")
pca.sex.scores <- bind_cols(data, pca.scores)
```

Now we can recreate the same plot as above but not in the tidyverse:

```{r chunk46, echo=TRUE, eval=TRUE, message=FALSE}
ggplot(pca.sex.scores, aes(Comp1, Comp2, colour = sex)) + geom_point(size = 3) + stat_ellipse(level = 0.66) + coord_fixed() + labs(x = "Principal Component 1", y = "Principal Component 2")
```

One of geomorph's more recent additions is `geomorph::picknplot.shape()`, an interactive function to select shapes on a principal component analysis. A PCA plot must be first created. We can then use the picknplot.shape function to select a specific example. For example:

```{r chunk47, echo=TRUE, eval=FALSE, message=FALSE}
plot(pca_patella, axis1 = 1, axis2 = 2)

plot1 <- plot(pca_patella, axis1 = 1, axis2 = 2)

picknplot.shape(plot1, method = "vector", links = patella_links)
```

Alternatively, we can use `geomorph::plotRefToTarget()`:

```{r chunk48, echo=TRUE, eval=FALSE, message=FALSE}
plotRefToTarget(pca_patella$shapes$shapes.comp1$min, pca_patella$shapes$shapes.comp1$max)
```

Now we have an idea of the specific shape changes between sex, let's perform a Procrustes ANOVA and see if our null hypothesis, of morphological correspondence between sex, is accepted. We first need to construct a data frame, to hold all our data, and then perform a Procrustes ANOVA like before:  

```{r chunk49, echo=TRUE, eval=TRUE, message=FALSE}
df_patella <- geomorph.data.frame(gpa_patella, sex = patella_dataset$sex)

anova(procD.lm(coords ~ sex, data = df_patella))
```

So we can reject the null hypothesis and conclude that there is a difference in the morphology of patella with respect to sex. 

One final thing we will do here is produce a hierarchical cluster of our patella, so we can examine which are closest. This may be useful with other forms of data (e.g. age, family or occupation). To do this we can first create a tibble of our Procrustes coordinates and then use the `stats::hclust` and `stats::dist` to perform a hierarchical cluster analysis on a distance matrix of our coordinates.

```{r chunk50, echo=TRUE, eval=TRUE, message=FALSE}
coords_gpa <- as_tibble(two.d.array(gpa_patella$coords), rownames = "rownames") %>% column_to_rownames("rownames")

plot(hclust(dist(coords_gpa)), hang = -1, cex = 0.6)
```

## **Concluding remarks**

There are  many others way to conduct what has been performed above, so don't treat the code as law. However, in exploring a number of different studies, and through the use of different packages, this guide/tutorial has hoped to highlight the analytical potential of geometric morpometrics. In each of these case studies, there was plenty more to discover; we have only began to scratch at the capabilities of the datasets collected here, and any number of exploratory and analytical procedures could be further performed.  

## References

Vestergaard, C. and Hoggard, C.S. (2019). A Novel Geometric Morphometric (GMM) Application to the Study of Bronze Age Tutuli. *Danish Journal of Archaeology*, 8: 5-28.  

Kovarovic, K., Aiello, L.C., Cardini, A. and Lockwood, C.A. 2011. Discriminant function analyses in archaeology: Are classification rates too good to be true? *Journal of Archaeological Science*, 38(11): 3006–3018.  